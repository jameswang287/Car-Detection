{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of car_detection_resnet.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jameswang287/Car-Detection/blob/master/car_detection_resnet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F9UoJEZvs12r",
        "colab_type": "text"
      },
      "source": [
        "**Car Make and Model Detection**\n",
        "James Wang\n",
        "\n",
        "README: https://people.ucsc.edu/~jwang402/car_det\n",
        "\n",
        "PyTorch\n",
        "\n",
        "Note: Run all cells in order in Google Colab for functionality.\n",
        "Only tested on **Google Colab** with **GPU runtime**.\n",
        "\n",
        "Requires NVIDIA CUDA Support\n",
        "\n",
        "**Import all necessary packages:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BMa4_fZ0s2ot",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tarfile\n",
        "import os\n",
        "import csv\n",
        "import time\n",
        "import torch\n",
        "import json\n",
        "from random import randint\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "import PIL.Image\n",
        "from scipy.io import loadmat\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms, models\n",
        "import torchvision.models as models\n",
        "from matplotlib.ticker import FormatStrFormatter\n",
        "from google.colab.patches import cv2_imshow\n",
        "import matplotlib.image as mpimg \n",
        "from matplotlib.pyplot import imshow\n",
        "from IPython.display import Image\n",
        "%matplotlib inline\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89138X226gIa",
        "colab_type": "text"
      },
      "source": [
        "**Download and extract files from Stanford University Repo**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BVDxvsoF6c2m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "outputId": "c07701ba-759a-4248-9e89-2a28b27e7b9d"
      },
      "source": [
        "#Download full training data (~935 MB)\n",
        "!wget --no-check-certificate \\\n",
        "    http://imagenet.stanford.edu/internal/car196/cars_train.tgz \\\n",
        "    -O /tmp/cars_train.tgz #downloaded directory\n",
        "#extract training data to /tmp/train/\n",
        "train_tar = tarfile.open('/tmp/cars_train.tgz')\n",
        "train_tar.extractall('/tmp/train') # specify which folder to extract to\n",
        "train_tar.close()\n",
        "#directory looks like /tmp/train/cars_train/\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-06-24 01:50:43--  http://imagenet.stanford.edu/internal/car196/cars_train.tgz\n",
            "Resolving imagenet.stanford.edu (imagenet.stanford.edu)... 171.64.68.16\n",
            "Connecting to imagenet.stanford.edu (imagenet.stanford.edu)|171.64.68.16|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 979269282 (934M) [application/x-gzip]\n",
            "Saving to: ‘/tmp/cars_train.tgz’\n",
            "\n",
            "/tmp/cars_train.tgz 100%[===================>] 933.90M  3.12MB/s    in 11m 5s  \n",
            "\n",
            "2020-06-24 02:01:49 (1.40 MB/s) - ‘/tmp/cars_train.tgz’ saved [979269282/979269282]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1kEazl8RpiS9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 172
        },
        "outputId": "480a8f94-a0ad-4b29-908e-609de4331f76"
      },
      "source": [
        "#Download full testing data (~933MB)\n",
        "!wget --no-check-certificate \\\n",
        "    http://imagenet.stanford.edu/internal/car196/cars_test.tgz \\\n",
        "    -O /tmp/cars_test.tgz #downloaded directory\n",
        "#extract testing data to tmp/test/\n",
        "test_tar = tarfile.open('/tmp/cars_test.tgz')\n",
        "test_tar.extractall('/tmp/test') # specify which folder to extract to\n",
        "test_tar.close()\n",
        "#directory looks like /tmp/test/cars_test/\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-06-24 02:01:59--  http://imagenet.stanford.edu/internal/car196/cars_test.tgz\n",
            "Resolving imagenet.stanford.edu (imagenet.stanford.edu)... 171.64.68.16\n",
            "Connecting to imagenet.stanford.edu (imagenet.stanford.edu)|171.64.68.16|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 977350468 (932M) [application/x-gzip]\n",
            "Saving to: ‘/tmp/cars_test.tgz’\n",
            "\n",
            "/tmp/cars_test.tgz   77%[==============>     ] 726.93M   467KB/s    eta 3m 2s  "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q7TaWHKfpiX6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Download labels (~0.3MB)\n",
        "!wget --no-check-certificate \\\n",
        "    http://ai.stanford.edu/~jkrause/cars/car_devkit.tgz \\\n",
        "    -O /tmp/car_devkit.tgz\n",
        "Path(\"/tmp/annos\").mkdir(parents=True, exist_ok=True)\n",
        "!wget --no-check-certificate \\\n",
        "    https://people.ucsc.edu/~jwang402/carslabel/anno_test.csv \\\n",
        "    -O /tmp/annos/anno_test.csv\n",
        "#extract labels to /tmp/labels/\n",
        "label_tar = tarfile.open('/tmp/car_devkit.tgz')\n",
        "label_tar.extractall('/tmp/labels') # specify which folder to extract to\n",
        "label_tar.close()\n",
        "#directory looks like /tmp/labels/devkit/\n",
        "#devkit dir contains: cars_meta.mat, cars_test_annos.mat, \n",
        "#cars_train_annos.mat, eval_train.m, README, train_perfect_preds.txt\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u0XogZ7N-ZHE",
        "colab_type": "text"
      },
      "source": [
        "**Load Class Mapping**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "drj8_nMy-ZUz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Classes are assigned numerical value of 1-196, each\n",
        "#mapping to a string. Data from cars_meta matlab file\n",
        "#This applies to all data.\n",
        "meta = loadmat('/tmp/labels/devkit/cars_meta.mat')\n",
        "meta.keys()\n",
        "type(meta['class_names']),meta['class_names'].shape\n",
        "[item.flat[0] for item in meta['class_names'][0][0]]\n",
        "classes = [[row.flat[0] for row in line] for line in meta['class_names'][0]]\n",
        "classDict = {}\n",
        "classCount = 1\n",
        "for c in classes:\n",
        "    classDict.update({classCount:c[0]})\n",
        "    classCount = classCount + 1\n",
        "term = 0\n",
        "for num, model in classDict.items():\n",
        "    print('Class #', num,'Model String:', model)\n",
        "    term = term + 1\n",
        "    if term == 4:\n",
        "        break\n",
        "print('...')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mJv2Dohb8q53",
        "colab_type": "text"
      },
      "source": [
        "**Load labels**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NKDOdtYl8iD8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#LABELS FOR TRAINING DATA\n",
        "#contains bbox, class, and filename\n",
        "labelfile = loadmat('/tmp/labels/devkit/cars_train_annos.mat')\n",
        "labelfile.keys()\n",
        "type(labelfile['annotations']),labelfile['annotations'].shape\n",
        "type(labelfile['annotations'][0][0]),labelfile['annotations'][0][0].shape\n",
        "labelfile['annotations'][0][0]['bbox_x1'], labelfile['annotations'][0][0]['fname']\n",
        "[item.flat[0] for item in labelfile['annotations'][0][0]]\n",
        "\"\"\"\n",
        "The following variable 'trainLabels' contains a list of labels for \n",
        "every test image the format of each element is as follows:\n",
        "### bbox_x1, bbox_y1, bbox_x2, bbox_y2, class, filename\n",
        "\"\"\"\n",
        "trainLabels = [[row.flat[0] for row in line] for line in labelfile['annotations'][0]]\n",
        "#Outputting the table for readibility with pandas\n",
        "columns = ['boundingbox_x1', 'boundingbox_y1', 'boundingbox_x2', 'boundingbox_y2', 'class', 'fname']\n",
        "view = pd.DataFrame(trainLabels, columns=columns)\n",
        "view.head()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jL9bJbMS3JA-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#LABELS FOR TESTING DATA\n",
        "#Contains bbox and filename\n",
        "lf = loadmat('/tmp/labels/devkit/cars_test_annos.mat')\n",
        "lf.keys()\n",
        "type(lf['annotations']),lf['annotations'].shape\n",
        "type(lf['annotations'][0][0]),lf['annotations'][0][0].shape\n",
        "lf['annotations'][0][0]['bbox_x1'], lf['annotations'][0][0]['fname']\n",
        "[item.flat[0] for item in lf['annotations'][0][0]]\n",
        "\"\"\"\n",
        "The following variable 'testLabels' contains a list of labels for \n",
        "every test image the format of each element is as follows:\n",
        "### bbox_x1, bbox_y1, bbox_x2, bbox_y2, filename\n",
        "there is no class name in this set of labels\n",
        "\"\"\"\n",
        "testLabels = [[row.flat[0] for row in line] for line in lf['annotations'][0]]\n",
        "\n",
        "#Test labels class and fname\n",
        "with open('/tmp/annos/anno_test.csv') as csv_file:\n",
        "    read = csv.reader(csv_file, delimiter=',')\n",
        "    testDict = {}\n",
        "    classCount = 1\n",
        "    for row in read:\n",
        "        testDict.update({row[0]:row[5]})\n",
        "        classCount = classCount + 1\n",
        "    print(len(testDict), 'processed')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pW1OEYeQ48Su",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#What labels look like for Training vs Testing after processing\n",
        "print(\"Train Labels\")\n",
        "print(\"...\")\n",
        "for i in range(len(trainLabels) - 4, len(trainLabels)):\n",
        "    print(trainLabels[i])\n",
        "print(\"\\nTest Labels\")\n",
        "print(\"...\")\n",
        "for i in range(len(testLabels) - 4, len(testLabels)):\n",
        "    print(testLabels[i])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGZjEFSnpU34",
        "colab_type": "text"
      },
      "source": [
        "**Preprocess Images**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWdQLf6eUQI4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "Preprocess Training Images\n",
        "Gets all training images and crops by bounding box, saves to a new directory\n",
        "The directory housing training image has subdirectories named by class name\n",
        "with each corresponding image in the corresponding folder\n",
        "Saves ~7% of images for validation\n",
        "\"\"\"\n",
        "print(len(trainLabels), \"images to process.\")\n",
        "Path(\"/tmp/processedTrain\").mkdir(parents=True, exist_ok=True)\n",
        "Path(\"/tmp/processedValidation\").mkdir(parents=True, exist_ok=True)\n",
        "count = 1\n",
        "for l in trainLabels:\n",
        "    print('Processing image', count, 'of', len(trainLabels))\n",
        "    #bbox\n",
        "    x1 = l[0]\n",
        "    y1 = l[1]\n",
        "    x2 = l[2]\n",
        "    y2 = l[3]\n",
        "    class_num = l[4]\n",
        "    filename = l[5]\n",
        "    address = \"/tmp/train/cars_train/\" + filename\n",
        "    classAppend = classDict.get(class_num) + '/'\n",
        "    if count < 7000:\n",
        "        saveDir = \"/tmp/processedTrain/\" + classAppend\n",
        "    else:\n",
        "        saveDir = \"/tmp/processedValidation/\" + classAppend\n",
        "    im = PIL.Image.open(address)\n",
        "    region = im.crop((x1, y1, x2, y2))\n",
        "    Path(saveDir).mkdir(parents=True, exist_ok=True)\n",
        "    saveAddress = saveDir + filename\n",
        "    region.save(saveAddress)    \n",
        "    print('Saved', saveAddress)\n",
        "    count = count + 1\n",
        "print(\"------------------------\")\n",
        "print(\"Training images preprocessing complete.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6VJKkkWP5RJo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "Preprocess Testing Images\n",
        "Gets all training images and crops by bounding box, saves to a new directory\n",
        "\"\"\"\n",
        "print(len(testLabels), \"images to process.\")\n",
        "Path(\"/tmp/processedTest\").mkdir(parents=True, exist_ok=True)\n",
        "Path(\"/tmp/boundedTest\").mkdir(parents=True, exist_ok=True)\n",
        "count = 1\n",
        "for l in testLabels:\n",
        "    print('Processing image', count, 'of', len(testLabels))\n",
        "    x1 = l[0]\n",
        "    y1 = l[1]\n",
        "    x2 = l[2]\n",
        "    y2 = l[3]\n",
        "    filename = l[4]\n",
        "    c_num = testDict.get(filename)\n",
        "    classAppend = classDict.get(int(c_num)) + '/'\n",
        "    address = \"/tmp/test/cars_test/\" + filename\n",
        "    saveDir = \"/tmp/processedTest/\" + classAppend\n",
        "    im = PIL.Image.open(address)\n",
        "    region = im.crop((x1, y1, x2, y2))\n",
        "    Path(saveDir).mkdir(parents=True, exist_ok=True)\n",
        "    saveAddress = saveDir + filename\n",
        "    saveAddress2 = \"/tmp/boundedTest/\" + filename\n",
        "    region.save(saveAddress2)    \n",
        "    print('Saved', saveAddress2)\n",
        "    region.save(saveAddress)    \n",
        "    print('Saved', saveAddress)\n",
        "    count = count + 1\n",
        "print(\"------------------------\")\n",
        "print(\"Testing images preprocessing complete.\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-TizduK3P2DM",
        "colab_type": "text"
      },
      "source": [
        "**Data is now saved as follows:**\n",
        "\n",
        "variables: trainLabel, testLabel (all have to be cropped)\n",
        "\n",
        "preprocessed data directories:\n",
        "\n",
        "training data: /tmp/processedTrain/Chevrolet Corvette Convertible 2012/06923.jpg\n",
        "\n",
        "validation data: /tmp/processedValidation/GMC Savana Van 2012/08131.jpg\n",
        "\n",
        "testing data: /tmp/boundedTest/08040.jpg\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xnQjoI7yv-O0",
        "colab_type": "text"
      },
      "source": [
        "**Preprocessed Image Demo**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "haMsrnwAriRK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#ORIGINAL TRAIN IMAGE, randomly selected\n",
        "rand = str(randint(1, len(trainLabels)-2000)).zfill(5)\n",
        "fname = rand + \".jpg\"\n",
        "print(fname)\n",
        "f = '/tmp/train/cars_train/' + fname\n",
        "im1_before = mpimg.imread(f)\n",
        "imshow(im1_before)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WnTA7ZKiwPfl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#PROCESSED TRAIN IMAGE\n",
        "for l in trainLabels:\n",
        "    if fname == l[5]:\n",
        "        c_num = int(l[4])\n",
        "        clAppend = str(classDict.get(c_num)) + '/'\n",
        "        app = clAppend + fname\n",
        "        f2 = '/tmp/processedTrain/' + app\n",
        "        im1_after = mpimg.imread(f2)\n",
        "        imshow(im1_after)\n",
        "        break\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GnlCQF-39RQ-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#ORIGINAL TEST IMAGE \n",
        "im1_before = mpimg.imread(\"/tmp/test/cars_test/08041.jpg\")\n",
        "imshow(im1_before)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kj6wTjw-9RTh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#PROCESSED TEST IMAGE \n",
        "im1_before = mpimg.imread(\"/tmp/boundedTest/08041.jpg\")\n",
        "imshow(im1_before)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fLJaFukb9H55",
        "colab_type": "text"
      },
      "source": [
        "**Transform and load**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQKHOGpVzT6e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "Prepare dataset for loading into model. First transform images with flips and\n",
        "rotations for robust model, then create loader with ImageFolder. Images will\n",
        "be shuffled as well to ensure order doesn't matter.\n",
        "\"\"\"\n",
        "def getTrainLoad(directory):\n",
        "    data = datasets.ImageFolder(directory, \n",
        "                                transform = transforms.Compose([transforms.Resize((244,244)),\n",
        "                                transforms.RandomRotation(30),\n",
        "                                transforms.RandomHorizontalFlip(),\n",
        "                                transforms.ToTensor(),\n",
        "                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]))\n",
        "    return torch.utils.data.DataLoader(data, batch_size=128, shuffle=True)\n",
        "\n",
        "def getTestLoad(directory):\n",
        "    data = datasets.ImageFolder(directory,\n",
        "                                transform = transforms.Compose([transforms.Resize((244,244)),\n",
        "                                transforms.CenterCrop(224),\n",
        "                                transforms.ToTensor(),\n",
        "                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]))\n",
        "    return torch.utils.data.DataLoader(data, batch_size=32, shuffle=True)\n",
        "trainLoad = getTrainLoad('/tmp/processedTrain')\n",
        "validLoad = getTestLoad('/tmp/processedValidation')\n",
        "testLoad = getTestLoad('/tmp/processedTest/')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BaOi8O0l6ln5",
        "colab_type": "text"
      },
      "source": [
        "**Transfer Learning - Resnet34 Implementation**\n",
        "\n",
        "**Model Creation**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQaHhAyuopDA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = models.resnet34(pretrained=True)\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Linear(num_ftrs, 196)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "lrscheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', patience=3, threshold = 0.9)\n",
        "device = 'cuda'\n",
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PHSNCJ7gyzfp",
        "colab_type": "text"
      },
      "source": [
        "**Train**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DkI3i5vpy5IS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "start = time.time()\n",
        "epochs = 10\n",
        "iterations = 0\n",
        "val = 35\n",
        "model.to(device)\n",
        "model.train()\n",
        "\n",
        "def validation(model, validloader, criterion):\n",
        "    valid_loss = 0\n",
        "    accuracy = 0\n",
        "    model.to(device)\n",
        "    for i, (images, labels) in enumerate(validloader):\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        output = model.forward(images)\n",
        "        valid_loss = valid_loss + criterion(output, labels).item()\n",
        "        ps = torch.exp(output)\n",
        "        equality = (labels.data == ps.max(dim=1)[1])\n",
        "        accuracy = accuracy + equality.type(torch.FloatTensor).mean()\n",
        "    return valid_loss, accuracy\n",
        "\n",
        "v_loss_hist = list()\n",
        "tr_loss_hist = list()\n",
        "v_acc_hist = list()\n",
        "\n",
        "for e in range(epochs):\n",
        "    running_loss = 0\n",
        "    for i, (inputs, labels) in enumerate(trainLoad):\n",
        "        iterations += 1\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model.forward(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "        #validation\n",
        "        if iterations % val == 0:\n",
        "            model.eval()\n",
        "            with torch.no_grad():\n",
        "                valid_loss, accuracy = validation(model, validLoad, criterion)\n",
        "            if (e + 1) > len(v_loss_hist):\n",
        "                v_loss_hist.append(round(valid_loss/len(validLoad),3))\n",
        "                tr_loss_hist.append(round(running_loss/val,3))\n",
        "                v_acc_hist.append(round(float(accuracy/len(validLoad)),3))\n",
        "            print(f\"Epoch #  {e+1}, \\\n",
        "            Valid Loss: {round(valid_loss/len(validLoad),5)}, \\\n",
        "            Training Loss: {round(running_loss/val,5)}, \\\n",
        "            Valid Accuracy: {round(float(accuracy/len(validLoad)),5)}\")\n",
        "            model.train()\n",
        "            lrscheduler.step(accuracy * 100)\n",
        "end = time.time()\n",
        "print(\"Training Complete.\")\n",
        "print(\"Training time in seconds:\", end - start)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kMOvvoCF55Yc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(tr_loss_hist)\n",
        "plt.title('Training Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Number of epochs')\n",
        "plt.legend(['train'], loc='upper left')\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oRAXeGBGL-EY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(v_loss_hist)\n",
        "plt.title('Validation Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Number of epochs')\n",
        "plt.legend(['train'], loc='upper left')\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZYQRpBNL-LO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(v_acc_hist)\n",
        "plt.title('Validation Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Number of epochs')\n",
        "plt.legend(['train'], loc='upper left')\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9wRAP7-Sy5Me",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.to(device)\n",
        "\"\"\"\n",
        "Tests model accuracy with test images\n",
        "\"\"\"\n",
        "start = time.time()\n",
        "total = 0\n",
        "correct = 0\n",
        "acc_hist = list()\n",
        "tot_hist = list()\n",
        "with torch.no_grad():\n",
        "    for data in testLoad:\n",
        "        images, labels = data\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, guess = torch.max(outputs.data, 1) \n",
        "        total = total + labels.size(0) #total num of images\n",
        "        correct = correct + (guess == labels).sum().item() #number correct\n",
        "        acc_hist.append(correct)\n",
        "        tot_hist.append(total)\n",
        "end = time.time()\n",
        "print(\"Total images tested in model:\", len(testLabels))\n",
        "print(\"Total accurate predictions:\", correct)\n",
        "print(f\"Accuracy of model w/ full test dataset fed: {round(100 * correct / total,8)}%\")\n",
        "print(\"Testing time in seconds:\", end - start)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V60-5ZtnDWRP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(acc_hist)\n",
        "plt.plot(tot_hist)\n",
        "plt.title('Total Images Tested vs Correct Guesses')\n",
        "plt.ylabel('# Images Tested')\n",
        "plt.xlabel('time')\n",
        "plt.legend(['# correct guesses', '# of images tested'], loc='upper left')\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "epKJYpcdXoYP",
        "colab_type": "text"
      },
      "source": [
        "**Make a CPU copy of the Model for testing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ObU1b4Qi-GBF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#make a copy of the model to change from gpu to cpu.\n",
        "import copy\n",
        "model_copy = copy.deepcopy(model)\n",
        "model_copy.to('cpu')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QmPAI04G4IdI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def find_classes(dir):\n",
        "    classes = os.listdir(dir)\n",
        "    classes.sort()\n",
        "    class_to_idx = {classes[i]: i for i in range(len(classes))}\n",
        "    return classes, class_to_idx\n",
        "classes, idx = find_classes(\"/tmp/processedTest/\")\n",
        "\n",
        "def predict(image, model, topk=5):\n",
        "    #open image and change to np form//cpu consideration\n",
        "    pil_in = PIL.Image.open(image)\n",
        "    transform = transforms.Compose([transforms.Resize((244,244)),\n",
        "                                    transforms.CenterCrop(224),\n",
        "                                    transforms.ToTensor(),\n",
        "                                    transforms.Normalize([0.485, 0.456, 0.406], \n",
        "                                                         [0.229, 0.224, 0.225])])\n",
        "    pilTrans = transform(pil_in)\n",
        "    img = np.array(pilTrans)\n",
        "    img_tensor = torch.from_numpy(img).type(torch.FloatTensor) #np to tensor\n",
        "    dimen = img_tensor.unsqueeze_(0)\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        output = model.forward(dimen)\n",
        "    probs_top = output.topk(topk)[0]\n",
        "    top_prediction = output.topk(topk)[1]\n",
        "    p = np.array(top_prediction)[0]\n",
        "    o_guesses = np.array(top_prediction)[0]\n",
        "    return p, o_guesses"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ocn1vmKtXf6t",
        "colab_type": "text"
      },
      "source": [
        "**Randomly pick a test image to predict**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M6g2jcrV6huj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "random_test_image = str(str(randint(1, len(testLabels))).zfill(5)) + '.jpg'\n",
        "image_to_classify = \"/tmp/boundedTest/\" + random_test_image\n",
        "device = ('cpu')\n",
        "start = time.time()\n",
        "tp, ps = predict(image_to_classify, model_copy, topk=5)\n",
        "print(\"Randomly chosen file to classify:\",image_to_classify)\n",
        "end = time.time()\n",
        "print(\"Seconds elapsed for prediction:\", end - start)\n",
        "print(\"*******************************\")\n",
        "print(\"FIRST GUESS: \",classes[ps[0]])\n",
        "print(\"*******************************\")\n",
        "print(\"Might also be:\", classes[ps[1]])\n",
        "print(\"Might also be:\", classes[ps[2]])\n",
        "print(\"Might also be:\", classes[ps[3]])\n",
        "print(\"Might also be:\", classes[ps[4]], \"\\n\")\n",
        "gimg = mpimg.imread(image_to_classify)\n",
        "imshow(gimg)\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}